{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DCGAN_Example.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPQQrw/KQh/k1r258rSqmxi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/datavzch/GANWS21/blob/main/DCGAN_Example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNyHtSzZYq7L"
      },
      "source": [
        "# **Import Required Libraries**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1R01wbeFY2O7"
      },
      "source": [
        "# Load required Libraries\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import tensorflow.keras as keras\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import os\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPoQthLdZSEM"
      },
      "source": [
        "# **Define Discriminator and Generator**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FkhEgWSIZY6P"
      },
      "source": [
        "# The discriminator model takes a sample image (from our dataset) as input and outputs a binary classification prediction.\n",
        "# Input: 32 x 32 pixels 3 color channel (rgb) image [32,32,3]\n",
        "# Output: Binary classification (0.0 to 1.0 - is it real or fake).\n",
        "\n",
        "def define_discriminator(input_shape=(32,32,3)):\n",
        "    model = keras.models.Sequential()\n",
        "    # The discriminator is composed of a set convolutional layers, \n",
        "    # 1 normal convolutional layer followed by a set of \n",
        "    # 3 convolutional layers with a 2 x 2 stride. Together this layers \n",
        "    # Downsample the image from 32 x 32 x 3 all the way to 4 x 4 x 3.\n",
        "    # Input is a 32*32*3 image\n",
        "    model.add(keras.layers.Conv2D(filters=64,kernel_size= (3,3),padding = 'same',input_shape = input_shape))\n",
        "    \n",
        "    # The use of LeakyReLU, dropout and Adam as well as their \n",
        "    # parameters are derived from the documentation and good practices suggestions. \n",
        "\n",
        "    model.add(keras.layers.LeakyReLU(0.2))\n",
        "    #model.add(keras.layers.Dropout(0.4))\n",
        "\n",
        "    # Downsample 16*16*3 image\n",
        "    model.add(keras.layers.Conv2D(filters= 128,kernel_size= (3,3),strides = (2,2),padding = 'same'))\n",
        "    model.add(keras.layers.LeakyReLU(0.2))\n",
        "    #model.add(keras.layers.Dropout(0.4))\n",
        "    \n",
        "    # Downsample 8*8*3 image\n",
        "    model.add(keras.layers.Conv2D(filters= 128,kernel_size= (4,4),strides = (2,2),padding = 'same'))\n",
        "    model.add(keras.layers.LeakyReLU(0.2))\n",
        "    #model.add(keras.layers.Dropout(0.4))\n",
        "    \n",
        "    # Downsample 4*4*3\n",
        "    model.add(keras.layers.Conv2D(filters= 256, kernel_size= (4,4), strides = (2,2), padding = 'same'))\n",
        "    model.add(keras.layers.LeakyReLU(0.2))\n",
        "    #model.add(keras.layers.Dropout(0.4))\n",
        "    \n",
        "    model.add(keras.layers.Flatten())\n",
        "    model.add(keras.layers.Dropout(0.4))\n",
        "\n",
        "    # We have a single node in the output layer with \n",
        "    # sigmoid activation function for the prediction (real or fake)\n",
        "\n",
        "    model.add(keras.layers.Dense(units= 1,activation = 'sigmoid'))\n",
        "    opt = keras.optimizers.Adam(learning_rate = 0.0002, beta_1 = 0.5)\n",
        "    model.compile(loss= 'binary_crossentropy', optimizer= opt, metrics = ['accuracy'])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "le-T9pFtZeQl"
      },
      "source": [
        "# The generator should output new fake images.\n",
        "# It takes a point in the latent space as input and outputs a 32 x 32 rgb image.\n",
        "# By assigning meaning to this latent points during the training process the latent space turns into a compressed repressentation of the dataset, generating \"real\" images.\n",
        "\n",
        "# Input: Point in latent space\n",
        "# Output: Rgb Image of 32 × 32 pixels (pixel values between -1 - 1)\n",
        "\n",
        "def define_generator(latent_dim):\n",
        "  # use a hidden dense layer to represent a low resolution version of the output (4 x 4 x 3).\n",
        "  # Give enough nodes (256 - Arbitrary - can be changed) for multiple versions \n",
        "  # of the output image (more feature maps).\n",
        "    model = keras.models.Sequential()\n",
        "    model.add(keras.layers.Dense(units= 256 * 4 * 4, input_dim = latent_dim)) #4 * 4 Arbitrary - Can be changed to test different results\n",
        "    model.add(keras.layers.LeakyReLU(0.2)) # LeakyReLU with a default slope of 0.2, reported as a good practice. \n",
        "    model.add(keras.layers.Reshape((4, 4, 256)))\n",
        "    # Pass the resulting feature maps into convolutional layer. \n",
        "    # Upsample the image to higher resolution.\n",
        "    # Use Conv2DTranspose for upsampling with a stride of 2x2 \n",
        "    # Repeat upsampling until achieving our 32 x 32 size goal.\n",
        "\n",
        "    # Upsample 8 * 8 \n",
        "    model.add(keras.layers.Conv2DTranspose(filters= 128, kernel_size = (4,4),padding='same', strides= (2,2)))\n",
        "    model.add(keras.layers.LeakyReLU(0.2))\n",
        "    # Upsample 16 * 16 \n",
        "    model.add(keras.layers.Conv2DTranspose(filters= 128, kernel_size = (4,4),padding='same', strides= (2,2)))\n",
        "    model.add(keras.layers.LeakyReLU(0.2))\n",
        "    # Upsample  32 * 32 now\n",
        "    model.add(keras.layers.Conv2DTranspose(filters= 128, kernel_size = (4,4),padding='same', strides= (2,2)))\n",
        "    model.add(keras.layers.LeakyReLU(0.2))\n",
        "\n",
        "    # Conv2D output layer with 3 filters (3 channels) with a kernel size of 3 \n",
        "    # for generation of single feature map with preserved dimensions (32 x 32 x 3)\n",
        "    # Use Than activation (good practice) to ensure the values are in range (from -1 to 1).\n",
        "    model.add(keras.layers.Conv2D(filters= 3, kernel_size= (3,3),padding = 'same', activation= 'tanh')) \n",
        "\n",
        "    # the generated images are completely random pixel values in [-1, 1], rescaled to [0, 1].\n",
        "    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhB741fsZrlJ"
      },
      "source": [
        "# **Define GAN**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uc688W-3Z1k2"
      },
      "source": [
        "# Generator weights are updated based in the discriminator performance. \n",
        "# The Gan function is defined to send the output from the generator to the discriminator, classified it, and then update generators weight. \n",
        "# Mark generator samples as real samples (trick discriminator)\n",
        "# Discriminator is marked as not trainable (to avoid over trainning with fake samples).\n",
        "def define_GAN(g_model, d_model):\n",
        "    d_model.trainable = False\n",
        "    model = keras.models.Sequential()\n",
        "    model.add(g_model)\n",
        "    model.add(d_model)\n",
        "    opt = keras.optimizers.Adam(learning_rate= 0.0002,beta_1= 0.5)\n",
        "    model.compile(loss= 'binary_crossentropy', optimizer= opt)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6B56u-KwZ68I"
      },
      "source": [
        "# **Generate Sample**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1Zcmx1qZ2rh"
      },
      "source": [
        "# Canadian Institute For Advanced Research dataset of 60,000 32 × 32 pixel color photographs of objects from 10 classes.\n",
        "# https://www.cs.toronto.edu/~kriz/cifar.html\n",
        "def load_data():\n",
        "    (X_train, _), (_, _) = keras.datasets.cifar10.load_data()\n",
        "    return X_train\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UJXZt7bZ__z"
      },
      "source": [
        "# generate points in latent space as input for the generator\n",
        "def generate_latent_points(latent_dim, n_samples):\n",
        "    X = np.random.randn(latent_dim * n_samples) # generate points in the latent space\n",
        "    X = X.reshape((n_samples, latent_dim)) # reshape into a batch of inputs for the network\n",
        "    return X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rngtPb_8aCUX"
      },
      "source": [
        "# select real samples\n",
        "def generate_real_sample(n_samples):\n",
        "    data = load_data() #we are loading the data withouth labels\n",
        "    ix = np.random.randint(0,data.shape[0], n_samples)\n",
        "    X = data[ix] # retrieve selected random images\n",
        "    X = X.reshape((n_samples, 32, 32, 3)).astype('float32')\n",
        "    X = (X - 127.5) / 127.5 # scale from [0,255] to [-1,1]\n",
        "    y = np.ones((n_samples, 1)) # create real class labels\n",
        "    return X, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJU3cdy9incz"
      },
      "source": [
        "# use the generator to generate n fake examples, with class labels\n",
        "def generate_fake_sample(g_model, latent_dim, n_samples):\n",
        "    x_input = generate_latent_points(latent_dim= latent_dim,n_samples= n_samples)  # generate points in latent space\n",
        "    X = g_model.predict(x_input) # predict outputs\n",
        "    y = np.zeros((n_samples, 1)) # create class labels \n",
        "    return X, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkq3fapSaaId"
      },
      "source": [
        "# **Summarize and Plot**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGidFu8JaFJ8"
      },
      "source": [
        "# create and save a plot of generated images\n",
        "def save_plot(x_input, epoch, n=7):\n",
        "    x_input = (x_input + 1.0) / 2.0\n",
        "    filename = f'generated_{epoch + 1}.png'\n",
        "    for i in range(n*n):\n",
        "        plt.subplot(n, n, i+1)\n",
        "        plt.imshow(x_input[i,:,:,:])\n",
        "        plt.axis('off')\n",
        "    plt.savefig(filename)\n",
        "    plt.show()\n",
        "    plt.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhPT82txi3G8"
      },
      "source": [
        "# Evaluate discriminator, plot generated images, save generator model\n",
        "def summarize_the_model(g_model, d_model, epoch, latent_dim, n_samples):\n",
        "    X_real, y_real = generate_real_sample(n_samples= n_samples)\n",
        "    X_fake, y_fake = generate_fake_sample(g_model= g_model,\n",
        "                                          latent_dim= latent_dim,\n",
        "                                          n_samples= n_samples)\n",
        "    print(f'Accuracy on real data: {d_model.evaluate(X_real, y_real, verbose= 0)}')\n",
        "    print(f'Accuracy on fake data: {d_model.evaluate(X_fake, y_fake, verbose= 0)}')\n",
        "    filename = f'model_e_{epoch + 1}.h5'\n",
        "    save_plot(x_input= X_fake,\n",
        "              epoch= epoch)\n",
        "    \n",
        "    g_model.save(filename)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HnsG1nvjanEE"
      },
      "source": [
        "# **Model Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ik0Pof73awRO"
      },
      "source": [
        "# train the generator and discriminator\n",
        "def train_GAN(gan_model, g_model, d_model, dataset_len, latent_dim, iters= 200, batch_size= 256):\n",
        "    half_batch = int(batch_size / 2)\n",
        "    batch_per_epoch = int(dataset_len / batch_size)\n",
        "    for i in range(iters):\n",
        "        for j in range(batch_per_epoch):\n",
        "            X_real, y_real = generate_real_sample(n_samples= half_batch)\n",
        "            X_fake, y_fake = generate_fake_sample(g_model= g_model,\n",
        "                                                  latent_dim= latent_dim,\n",
        "                                                  n_samples= half_batch)\n",
        "            X, y = np.vstack((X_real, X_fake)), np.vstack((y_real, y_fake))\n",
        "            d_model.train_on_batch(X, y)\n",
        "            \n",
        "            x_gan = generate_latent_points(latent_dim= latent_dim,\n",
        "                                             n_samples= batch_size)\n",
        "            y_gan = np.ones((batch_size, 1))\n",
        "            gan_model.train_on_batch(x_gan, y_gan)\n",
        "            if not j%100: \n",
        "                print(f'Epoch: {i+1}, Batches/Epoch: {j+1}/{batch_per_epoch}')\n",
        "                summarize_the_model(g_model= g_model,\n",
        "                                    d_model= d_model,\n",
        "                                    epoch= i,\n",
        "                                    latent_dim= latent_dim,\n",
        "                                    n_samples= batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8W_L1Jsa01H"
      },
      "source": [
        "# size of the latent space\n",
        "latent_dim = 100\n",
        "g_model = define_generator(latent_dim= latent_dim) \n",
        "d_model = define_discriminator()\n",
        "gan_model = define_GAN(d_model= d_model,\n",
        "                       g_model= g_model)\n",
        "train_GAN(gan_model= gan_model, \n",
        "          g_model= g_model,\n",
        "          d_model= d_model,\n",
        "          dataset_len= load_data().shape[0],\n",
        "          latent_dim= latent_dim)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBKPUZaLweZv"
      },
      "source": [
        "# **Prediction on resulting model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJws1m_9wrVy"
      },
      "source": [
        "# Load pretrained model \n",
        "model = keras.models.load_model('./model_e_99.h5', compile= False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "robhqIUUw6rv"
      },
      "source": [
        "# Plot pre trained model prediction\n",
        "vec = np.array([[np.cos(_) for _ in range(100)]])\n",
        "X = ( model.predict(vec) + 1 ) / 2.0\n",
        "plt.imshow(X[0])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QF5ruLbxByu"
      },
      "source": [
        "# Define plotting for 49 image sample\n",
        "def plotModel(model, n_samples=49):\n",
        "    plt.figure(figsize=(18,9))\n",
        "    for i in range(n_samples):\n",
        "        ran = np.random.randn(n_samples, 100)\n",
        "        sqrt = int(np.sqrt(n_samples))\n",
        "        plt.subplot(sqrt, sqrt, i+1)\n",
        "        X = model.predict(ran)\n",
        "        X = (X + 1) / 2.0\n",
        "        plt.imshow(X[0])\n",
        "        plt.axis('off')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eS0_daSFxNom"
      },
      "source": [
        "plotModel(model, n_samples= 25)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}